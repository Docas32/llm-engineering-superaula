{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4a77500",
   "metadata": {},
   "source": [
    "#Fundamentos de LLM Engineering & Gestão de Contexto\n",
    "Este notebook faz parte dos meus estudos avançados em LLM Engineering, RAG & AI Agents. O objetivo principal é demonstrar a implementação técnica de chamadas de API estruturadas, utilizando as melhores práticas de mercado para garantir segurança, escalabilidade e controle comportamental de modelos de linguagem de larga escala (LLMs).\n",
    "\n",
    "##Destaques Técnicos\n",
    "Integração com Gemini 2.5 Flash: Implementação utilizando o SDK v1.0+ (google-genai), focando em alta performance e baixa latência para aplicações industriais.\n",
    "\n",
    "Arquitetura de Prompt com System Instructions: Uso de instruções de sistema nativas para modularizar personalidades da IA, garantindo consistência no tom de voz e redução de alucinações.\n",
    "\n",
    "Segurança de Dados: Gestão de credenciais sensíveis através de variáveis de ambiente com python-dotenv, seguindo padrões de segurança para ambientes produtivos.\n",
    "\n",
    "Contextualização Setorial: Configuração de personas voltadas para a análise de licitações técnicas e engenharia, conectando a IA com desafios reais do setor produtivo brasileiro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b191a5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.genai import Client, types\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec8a1bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0421372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa o cliente novo\n",
    "# Garanta que o cliente saiba que é para usar o backend do AI Studio\n",
    "client = Client(api_key=os.environ.get(\"GOOGLE_API_KEY\"), http_options={'api_version': 'v1beta'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8612b61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mandando mensagem para OpenAI: Escreva um Poema para minha mae Helena parabenizando a pelos seus 62 anos!\n"
     ]
    }
   ],
   "source": [
    "#Definindo uma mensagem que queremos enviar para o usuario\n",
    "my_message = \"Escreva um Poema para minha mae Helena parabenizando a pelos seus 62 anos!\"\n",
    "print(f\"mandando mensagem para OpenAI: {my_message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8de25afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"models/gemini-2.5-flash\", \n",
    "    contents=my_message\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb844288",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Vamos imprimir a resposta\n",
    "print(\"\\nAI: \\n\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df0a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in client.models.list():\n",
    "#     print(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0d82961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Você é um Engenheiro de IA Sênior com 15 anos de experiência. Sua linguagem é técnica, precisa, mas encorajadora. Ao explicar conceitos, use analogias de engenharia e sempre forneça exemplos de código limpo.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dando personalidade a nossa IA fazemos isso utilizando system prompt\n",
    "# sendo system prompt uma instrucao especial com o role 'system' colocando no inicio da mensagem\n",
    "\n",
    "# Dicionário de Personalidades para Prompts\n",
    "character_personalities = {\n",
    "    \"mentor_tecnico\": (\n",
    "        \"Você é um Engenheiro de IA Sênior com 15 anos de experiência. \"\n",
    "        \"Sua linguagem é técnica, precisa, mas encorajadora. Ao explicar conceitos, \"\n",
    "        \"use analogias de engenharia e sempre forneça exemplos de código limpo.\"\n",
    "    ),\n",
    "    \"analista_negocios\": (\n",
    "        \"Você é um consultor de estratégia focado em ROI e eficiência. \"\n",
    "        \"Sua comunicação é direta, baseada em tópicos (bullet points) e sempre \"\n",
    "        \"focada nos resultados práticos e viabilidade econômica de uma solução de IA.\"\n",
    "    ),\n",
    "    \"explicador_simples\": (\n",
    "        \"Você é um professor especializado em simplificar temas complexos (ELI5). \"\n",
    "        \"Evite jargões técnicos excessivos. Se precisar usar um termo técnico, \"\n",
    "        \"explique-o antes. Use um tom amigável e didático.\"\n",
    "    ),\n",
    "    \"agente_critico\": (\n",
    "        \"Você é um revisor de código rigoroso e pessimista. Seu objetivo é \"\n",
    "        \"encontrar falhas, vulnerabilidades de segurança e gargalos de performance \"\n",
    "        \"em arquiteturas RAG. Seja direto e aponte os problemas sem rodeios.\"\n",
    "    )\n",
    "}\n",
    "character_personalities[\"especialista_licitacoes\"] = (\n",
    "    \"Você é um especialista em direito administrativo e licitações brasileiras. \"\n",
    "    \"Sua função é analisar resumos de editais e identificar riscos jurídicos ou \"\n",
    "    \"oportunidades para empresas de engenharia. Seja extremamente analítico.\"\n",
    ")\n",
    "\n",
    "\n",
    "# Escolhendo a personalidade \n",
    "chosen_character = 'mentor_tecnico'\n",
    "system_instructions = character_personalities[chosen_character]\n",
    "system_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf80079",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_message =\"Quais as melhores habilidades para um engenheiro de IA em 2026?\"\n",
    "response = client.models.generate_content(\n",
    "    model=\"models/gemini-2.5-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_instructions, # Aqui entra a persona\n",
    "        temperature=0.7, # Adicionando controle de criatividade\n",
    "        top_p=0.95,\n",
    "    ),\n",
    "    contents=my_message\n",
    ")\n",
    "print(f\"--- Resposta como {chosen_character.upper()} ---\\n\")\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
